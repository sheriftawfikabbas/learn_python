{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7lVToPsNWVkikTYxba1EN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nxeBQByr_Sa0","colab_type":"text"},"source":["# Lab 10\n","\n","## Exercise 1:\n","\n","Let's have a go with the BBC website. Load the BBC News page and print out all of the links, then write a loop that visits and prints out the news titles in the page of each link."]},{"cell_type":"code","metadata":{"id":"XdfqnPy9_GmR","colab_type":"code","colab":{}},"source":["link = 'http://www.bbc.com/news'\n","\n","\n","from bs4 import BeautifulSoup\n","\n","import requests\n","response = requests.get(link)\n","data = response.text\n","\n","data_bs = BeautifulSoup(data)\n","\n","list_of_links = data_bs.find_all('a')\n","\n","# print('The list of links:',list_of_links)\n","\n","for l in list_of_links:\n","  link=l.get('href')\n","  if len(link) > 0:\n","    if link[0] == '/':\n","      print(link)\n","      response = requests.get(\"http://www.bbc.com\"+link)\n","      new_page = response.text\n","      new_bs = BeautifulSoup(new_page)\n","      list_of_titles = new_bs.find_all('h3')\n","      # print(list_of_titles)\n","      print(len(list_of_titles))\n","      for t in list_of_titles:\n","        if 'coronavirus' in t.text.lower()  or 'COVID' in t.text:\n","          print(t.text)\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5667atYcAF8L","colab_type":"text"},"source":["## Exercise 2: (Quiz)\n","\n","Extending the above exercise: write a loop inside the above loop that visits the second level pages. That is:\n","- Outer loop: visits pages 1, 2, 3, .. from the main page\n","- Inner loop: visits pages 1.1, 1.2, 1.3, .. from page 1, then 2.1, 2.2, 2.3, .. from page 2, etc."]},{"cell_type":"code","metadata":{"id":"KWcplwRuAyRR","colab_type":"code","colab":{}},"source":["link = 'http://www.bbc.com/news'\n","\n","\n","from bs4 import BeautifulSoup\n","\n","import requests\n","response = requests.get(link)\n","data = response.text\n","\n","data_bs = BeautifulSoup(data)\n","\n","list_of_links = data_bs.find_all('a')\n","\n","# print('The list of links:',list_of_links)\n","\n","for l in list_of_links:\n","  link=l.get('href')\n","  if len(link) > 0:\n","    if link[0] == '/':\n","      print(\"* \"+link)\n","      response = requests.get(\"http://www.bbc.com\"+link)\n","      new_page = response.text\n","      new_bs = BeautifulSoup(new_page)\n","      list_of_links_level2 = new_bs.find_all('a')\n","      for t in list_of_links_level2:\n","        print(\"*      \"+t.text)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8sd8wdMMAyZE","colab_type":"text"},"source":["## Exercise 3:\n","\n","Now, pick a news article, then view its source. Can you find the news text in the source?\n","\n","\n","\n"]}]}